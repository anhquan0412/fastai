{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callback.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Callbacks\n",
    "\n",
    "> Callbacks which work with a learner's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastai.test_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CollectDataCallback(Callback):\n",
    "    \"Collect all batches, along with `pred` and `loss`, into `self.data`. Mainly for testing\"\n",
    "    def before_fit(self): self.data = L()\n",
    "    def after_batch(self): \n",
    "        self.data.append(self.learn.to_detach((self.xb,self.yb,self.pred,self.loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CudaCallback(Callback):\n",
    "    \"Move data to CUDA device\"\n",
    "    def __init__(self, device=None): self.device = ifnone(device, default_device())\n",
    "    def before_batch(self): self.learn.xb,self.learn.yb = to_device(self.xb),to_device(self.yb)\n",
    "    def before_fit(self): self.model.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't normally need to use this Callback, because fastai's `DataLoader` will handle passing data to a device for you. However, if you already have a plain PyTorch DataLoader and can't change it for some reason, you can use this transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 22.621259689331055, 28.540876388549805, '00:00']\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "learn = synth_learner(cbs=CudaCallback)\n",
    "learn.model\n",
    "learn.fit(1)\n",
    "test_eq(next(learn.model.parameters()).device.type, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates()\n",
    "class WeightedDL(TfmdDL):\n",
    "    def __init__(self, dataset=None, bs=None, wgts=None, **kwargs):\n",
    "        super().__init__(dataset=dataset, bs=bs, **kwargs)\n",
    "        wgts = array([1.]*len(dataset) if wgts is None else wgts)\n",
    "        self.wgts = wgts/wgts.sum()\n",
    "\n",
    "    def get_idxs(self):\n",
    "        if self.n==0: return []\n",
    "        if not self.shuffle: return super().get_idxs()\n",
    "        return list(np.random.choice(self.n, self.n, p=self.wgts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@delegates(Datasets.dataloaders)\n",
    "def weighted_dataloaders(self:Datasets, wgts, bs=64, **kwargs):\n",
    "    xtra_kwargs = [{}] * (self.n_subsets-1)\n",
    "    return self.dataloaders(bs=bs, dl_type=WeightedDL, dl_kwargs=({'wgts':wgts}, *xtra_kwargs), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 160\n",
    "dsets = Datasets(torch.arange(n).float())\n",
    "dls = dsets.weighted_dataloaders(wgts=range(n), bs=16)\n",
    "learn = synth_learner(data=dls, cbs=CollectDataCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, nan, None, '00:01']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1)\n",
    "t = concat(*learn.collect_data.data.itemgot(0,0))\n",
    "plt.hist(t.numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates()\n",
    "class PartialDL(TfmdDL):\n",
    "    \"Select randomly partial quantity of data at each epoch\"\n",
    "    def __init__(self, dataset=None, bs=None, partial_n=None, **kwargs):\n",
    "        super().__init__(dataset=dataset, bs=bs, **kwargs)\n",
    "        self.partial_n = min(partial_n, self.n) if partial_n else None\n",
    "\n",
    "    def get_idxs(self):\n",
    "        if self.partial_n is None: return super().get_idxs()\n",
    "        return list(np.random.choice(self.n, self.partial_n, replace=False))\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.partial_n is None: return super().__len__()\n",
    "        return self.partial_n//self.bs + (0 if self.drop_last or self.partial_n%self.bs==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@delegates(Datasets.dataloaders)\n",
    "def partial_dataloaders(self:FilteredBase, partial_n, bs=64, **kwargs):\n",
    "    \"Create a partial dataloader `PartialDL` for the training set\"\n",
    "    xtra_kwargs = [{}] * (self.n_subsets-1)\n",
    "    return self.dataloaders(bs=bs, dl_type=PartialDL, dl_kwargs=({'partial_n':partial_n}, *xtra_kwargs), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsets.partial_dataloaders(partial_n=32, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dls[0])==2\n",
    "for batch in dls[0]:\n",
    "    assert len(batch[0])==16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 01a_losses.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 10b_tutorial.albumentations.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 18a_callback.training.ipynb.\n",
      "Converted 18b_callback.preds.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.vision.ipynb.\n",
      "Converted 24_tutorial.siamese.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.text.ipynb.\n",
      "Converted 39_tutorial.transformers.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 44_tutorial.tabular.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 46_tutorial.collab.ipynb.\n",
      "Converted 50_tutorial.datablock.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 61_tutorial.medical_imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 73_callback.captum.ipynb.\n",
      "Converted 74_callback.cutmix.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted dev-setup.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted quick_start.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
